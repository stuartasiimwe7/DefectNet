{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"data/pcb_dataset/images/\"\n",
    "output_dir = \"data/pcb_dataset/resized_images/\"\n",
    "classes = ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset preprocessing complete! All images are resized and saved.\n"
     ]
    }
   ],
   "source": [
    "# Loop through each defect class folder\n",
    "for class_name in os.listdir(image_dir):\n",
    "    class_path = os.path.join(image_dir, class_name)\n",
    "    \n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(class_path):\n",
    "        output_class_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)  # Create class subfolder in output\n",
    "        \n",
    "        # Process each image inside the class folder\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Skipping {img_name} (unable to read)\")\n",
    "                continue\n",
    "            \n",
    "            # Resize image to 640x640 for YOLO\n",
    "            img_resized = cv2.resize(img, (640, 640))\n",
    "            \n",
    "            # Save resized image in the corresponding output class folder\n",
    "            cv2.imwrite(os.path.join(output_class_dir, img_name), img_resized)\n",
    "\n",
    "print(\"✅ Dataset preprocessing complete! All images are resized and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_voc_to_yolo(xml_file, output_dir):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_size = root.find(\"size\")\n",
    "    img_w, img_h = int(image_size.find(\"width\").text), int(image_size.find(\"height\").text)\n",
    "\n",
    "    # Create corresponding label file\n",
    "    yolo_label_path = os.path.join(output_dir, image_name.replace(\".jpg\", \".txt\"))\n",
    "\n",
    "    with open(yolo_label_path, \"w\") as yolo_file:\n",
    "        for obj in root.findall(\"object\"):\n",
    "            class_name = obj.find(\"name\").text\n",
    "            if class_name not in classes:\n",
    "                continue  # Skip unknown classes\n",
    "            \n",
    "            class_idx = classes.index(class_name)\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "\n",
    "            x_min, y_min, x_max, y_max = map(int, [\n",
    "                bbox.find(\"xmin\").text, bbox.find(\"ymin\").text, \n",
    "                bbox.find(\"xmax\").text, bbox.find(\"ymax\").text\n",
    "            ])\n",
    "\n",
    "            x_center = (x_min + x_max) / (2.0 * img_w)\n",
    "            y_center = (y_min + y_max) / (2.0 * img_h)\n",
    "            width = (x_max - x_min) / img_w\n",
    "            height = (y_max - y_min) / img_h\n",
    "\n",
    "            yolo_file.write(f\"{class_idx} {x_center} {y_center} {width} {height}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_dir = \"data/pcb_dataset/Annotations/\"\n",
    "output_root_dir = \"data/pcb_dataset/yolo_labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All Pascal VOC annotations successfully converted to YOLO format!\n"
     ]
    }
   ],
   "source": [
    "# Process each class folder\n",
    "for class_name in os.listdir(xml_dir):\n",
    "    class_dir = os.path.join(xml_dir, class_name)\n",
    "\n",
    "    if os.path.isdir(class_dir):  # Ensure it's a directory\n",
    "        output_class_dir = os.path.join(output_root_dir, class_name)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        # Process each XML file in the class directory\n",
    "        for xml_file in os.listdir(class_dir):\n",
    "            if xml_file.endswith(\".xml\"):\n",
    "                convert_voc_to_yolo(os.path.join(class_dir, xml_file), output_class_dir)\n",
    "\n",
    "print(\"✅ All Pascal VOC annotations successfully converted to YOLO format!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data/pcb_dataset/train/\"\n",
    "val_dir = \"data/pcb_dataset/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data split into training and validation sets successfully!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "# Ensure class subdirectories in train/val exist\n",
    "for class_name in classes:\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
    "\n",
    "    # Find all jpg files for the current class\n",
    "    class_files = [f for f in os.listdir(os.path.join(output_dir, class_name)) if f.endswith('.jpg')]\n",
    "    total = len(class_files)\n",
    "    \n",
    "    # Shuffle and split data: 80% for training, 20% for validation\n",
    "    random.shuffle(class_files)\n",
    "    train_count = int(total * 0.8)\n",
    "\n",
    "    # Move 80% of images to the train directory\n",
    "    for i in range(train_count):\n",
    "        shutil.move(os.path.join(output_dir, class_name, class_files[i]), os.path.join(train_dir, class_name))\n",
    "\n",
    "    # Move remaining 20% to the validation directory\n",
    "    for i in range(train_count, total):\n",
    "        shutil.move(os.path.join(output_dir, class_name, class_files[i]), os.path.join(val_dir, class_name))\n",
    "\n",
    "print(\"✅ Data split into training and validation sets successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
